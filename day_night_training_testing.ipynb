{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *This project classifies the images on the fact that whether they are captured during day light or at night or in dim light*\n",
    "\n",
    "    - Images are taken from the internet\n",
    "    - Total 1700+ images are there, with 759 for day and rest for night.\n",
    "    - Image quantity and quality both are not at par for a deep neural network to be trained.\n",
    "    - This model can be tuned for better and accurate result with Keras tuner, Talos etc to optimize the hyperparameter             -- (currently machine limitation).\n",
    "    - Model accuracy can also be refined with more and better dataset.\n",
    "    - Computer Vision aapproach to determine the same using the BGR to HSV values and then finding a threshold to classify \n",
    "    -- can also be used, but it can be difficult to attain a greater accuracy for images with noise like cloudy time in day \n",
    "    --- or fog scenes.\n",
    "    - To refine model with more robustness to noise, we can augment the data and also add random noise in image pixels.\n",
    "    - Challenge : Need to label the data for training, if the data is humongous.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note : Please find the label below (The same is followed through out the notebook)\n",
    "\n",
    " >> 0 : Day \n",
    " \n",
    " >> 1 : Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing all the libraries\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from imutils import paths\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize to create the dataset\n",
    "image_names = []\n",
    "classes = []\n",
    "train_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "day_images = r\"S:\\\\Day_night_image_classification\\\\Image\\\\Day\\\\\"\n",
    "night_images = r\"S:\\\\Day_night_image_classification\\\\Image\\\\Night\\\\\"\n",
    "complete_images = r\"S:\\\\Day_night_image_classification\\\\Image\\\\Combined\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data Acquisition\n",
    "\"\"\" 0 for day and 1 for night \"\"\"\n",
    "for imagePath in paths.list_images(day_images):\n",
    "    image_names.append(imagePath.split('\\\\')[-1])\n",
    "    classes.append(0)\n",
    "for imagePath in paths.list_images(night_images):\n",
    "    image_names.append(imagePath.split('\\\\')[-1])\n",
    "    classes.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['image_names'] = image_names\n",
    "train_df['classes'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1722/1722 [00:32<00:00, 70.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#Converting image data into array\n",
    "train_image = []\n",
    "for i in tqdm(range(int((train_df.shape[0])))):\n",
    "    img = image.load_img(complete_images+str(train_df['image_names'][i]),target_size=(300,300))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1722, 300, 300, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizing the feature array dimensions\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1722, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating label array\n",
    "y = np.array(train_df.drop(['image_names'],axis=1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data in test and train for model validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(4, 4), activation=\"relu\", input_shape=(300,300,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(4, 4), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1205 samples, validate on 517 samples\n",
      "Epoch 1/20\n",
      "1205/1205 [==============================] - ETA: 2:10:20 - loss: 0.7464 - acc: 0.42 - ETA: 1:01:43 - loss: 1.9510 - acc: 0.49 - ETA: 38:50 - loss: 1.6498 - acc: 0.5208 - ETA: 27:23 - loss: 1.4612 - acc: 0.54 - ETA: 20:29 - loss: 1.3241 - acc: 0.55 - ETA: 15:53 - loss: 1.2116 - acc: 0.56 - ETA: 12:36 - loss: 1.1395 - acc: 0.58 - ETA: 10:07 - loss: 1.1005 - acc: 0.58 - ETA: 8:11 - loss: 1.0505 - acc: 0.5868 - ETA: 6:38 - loss: 1.0145 - acc: 0.584 - ETA: 5:22 - loss: 0.9788 - acc: 0.596 - ETA: 4:18 - loss: 0.9617 - acc: 0.597 - ETA: 3:24 - loss: 0.9348 - acc: 0.601 - ETA: 2:37 - loss: 0.9096 - acc: 0.604 - ETA: 1:57 - loss: 0.8898 - acc: 0.606 - ETA: 1:21 - loss: 0.8664 - acc: 0.613 - ETA: 49s - loss: 0.8498 - acc: 0.616 - ETA: 21s - loss: 0.8340 - acc: 0.62 - 471s 391ms/step - loss: 0.8207 - acc: 0.6266 - val_loss: 0.5358 - val_acc: 0.7408\n",
      "Epoch 2/20\n",
      "1205/1205 [==============================] - ETA: 21s - loss: 0.5308 - acc: 0.79 - ETA: 19s - loss: 0.4972 - acc: 0.82 - ETA: 18s - loss: 0.4797 - acc: 0.81 - ETA: 17s - loss: 0.4812 - acc: 0.80 - ETA: 16s - loss: 0.4701 - acc: 0.80 - ETA: 15s - loss: 0.4717 - acc: 0.81 - ETA: 13s - loss: 0.4669 - acc: 0.81 - ETA: 12s - loss: 0.4548 - acc: 0.81 - ETA: 11s - loss: 0.4458 - acc: 0.81 - ETA: 10s - loss: 0.4275 - acc: 0.82 - ETA: 9s - loss: 0.4205 - acc: 0.8267 - ETA: 8s - loss: 0.4120 - acc: 0.833 - ETA: 6s - loss: 0.4106 - acc: 0.834 - ETA: 5s - loss: 0.4106 - acc: 0.835 - ETA: 4s - loss: 0.3988 - acc: 0.841 - ETA: 3s - loss: 0.3892 - acc: 0.845 - ETA: 2s - loss: 0.3845 - acc: 0.847 - ETA: 0s - loss: 0.3718 - acc: 0.854 - 25s 21ms/step - loss: 0.3650 - acc: 0.8581 - val_loss: 0.1334 - val_acc: 0.9749\n",
      "Epoch 3/20\n",
      "1205/1205 [==============================] - ETA: 21s - loss: 0.2887 - acc: 0.93 - ETA: 19s - loss: 0.2771 - acc: 0.91 - ETA: 18s - loss: 0.2630 - acc: 0.91 - ETA: 17s - loss: 0.2322 - acc: 0.92 - ETA: 16s - loss: 0.2300 - acc: 0.92 - ETA: 15s - loss: 0.2187 - acc: 0.93 - ETA: 14s - loss: 0.2167 - acc: 0.93 - ETA: 12s - loss: 0.2102 - acc: 0.93 - ETA: 11s - loss: 0.1942 - acc: 0.94 - ETA: 10s - loss: 0.1832 - acc: 0.94 - ETA: 9s - loss: 0.1805 - acc: 0.9446 - ETA: 8s - loss: 0.1963 - acc: 0.942 - ETA: 6s - loss: 0.1916 - acc: 0.945 - ETA: 5s - loss: 0.1992 - acc: 0.944 - ETA: 4s - loss: 0.2133 - acc: 0.941 - ETA: 3s - loss: 0.2073 - acc: 0.942 - ETA: 2s - loss: 0.2159 - acc: 0.943 - ETA: 0s - loss: 0.2076 - acc: 0.946 - 26s 21ms/step - loss: 0.2058 - acc: 0.9461 - val_loss: 0.1492 - val_acc: 0.9381\n",
      "Epoch 4/20\n",
      "1205/1205 [==============================] - ETA: 20s - loss: 0.1484 - acc: 0.95 - ETA: 19s - loss: 0.1316 - acc: 0.95 - ETA: 18s - loss: 0.1298 - acc: 0.96 - ETA: 17s - loss: 0.1233 - acc: 0.96 - ETA: 16s - loss: 0.1205 - acc: 0.96 - ETA: 15s - loss: 0.1152 - acc: 0.97 - ETA: 13s - loss: 0.1144 - acc: 0.97 - ETA: 12s - loss: 0.1132 - acc: 0.97 - ETA: 11s - loss: 0.1083 - acc: 0.97 - ETA: 10s - loss: 0.1031 - acc: 0.97 - ETA: 9s - loss: 0.1076 - acc: 0.9744 - ETA: 7s - loss: 0.1344 - acc: 0.971 - ETA: 6s - loss: 0.1311 - acc: 0.971 - ETA: 5s - loss: 0.1297 - acc: 0.972 - ETA: 4s - loss: 0.1351 - acc: 0.968 - ETA: 3s - loss: 0.1310 - acc: 0.969 - ETA: 2s - loss: 0.1318 - acc: 0.969 - ETA: 0s - loss: 0.1332 - acc: 0.969 - 25s 21ms/step - loss: 0.1296 - acc: 0.9710 - val_loss: 0.0596 - val_acc: 0.9865\n",
      "Epoch 5/20\n",
      "1205/1205 [==============================] - ETA: 21s - loss: 0.0820 - acc: 0.98 - ETA: 19s - loss: 0.0915 - acc: 0.98 - ETA: 18s - loss: 0.0844 - acc: 0.97 - ETA: 17s - loss: 0.0810 - acc: 0.98 - ETA: 16s - loss: 0.0774 - acc: 0.98 - ETA: 15s - loss: 0.0752 - acc: 0.98 - ETA: 14s - loss: 0.0862 - acc: 0.98 - ETA: 12s - loss: 0.0887 - acc: 0.98 - ETA: 11s - loss: 0.0831 - acc: 0.98 - ETA: 10s - loss: 0.0778 - acc: 0.98 - ETA: 9s - loss: 0.0843 - acc: 0.9815 - ETA: 8s - loss: 0.1070 - acc: 0.976 - ETA: 6s - loss: 0.1037 - acc: 0.977 - ETA: 5s - loss: 0.1027 - acc: 0.976 - ETA: 4s - loss: 0.1029 - acc: 0.976 - ETA: 3s - loss: 0.1008 - acc: 0.976 - ETA: 2s - loss: 0.1072 - acc: 0.975 - ETA: 0s - loss: 0.1061 - acc: 0.975 - 25s 21ms/step - loss: 0.1051 - acc: 0.9759 - val_loss: 0.0637 - val_acc: 0.9729\n",
      "Epoch 6/20\n",
      "1205/1205 [==============================] - ETA: 21s - loss: 0.0550 - acc: 1.00 - ETA: 20s - loss: 0.0394 - acc: 1.00 - ETA: 18s - loss: 0.0354 - acc: 1.00 - ETA: 17s - loss: 0.0354 - acc: 1.00 - ETA: 16s - loss: 0.0350 - acc: 0.99 - ETA: 15s - loss: 0.0402 - acc: 0.99 - ETA: 14s - loss: 0.0452 - acc: 0.99 - ETA: 13s - loss: 0.0464 - acc: 0.99 - ETA: 11s - loss: 0.0443 - acc: 0.99 - ETA: 10s - loss: 0.0437 - acc: 0.99 - ETA: 9s - loss: 0.0458 - acc: 0.9915 - ETA: 8s - loss: 0.0683 - acc: 0.987 - ETA: 7s - loss: 0.0653 - acc: 0.988 - ETA: 5s - loss: 0.0628 - acc: 0.988 - ETA: 4s - loss: 0.0705 - acc: 0.987 - ETA: 3s - loss: 0.0674 - acc: 0.988 - ETA: 2s - loss: 0.0787 - acc: 0.984 - ETA: 1s - loss: 0.0813 - acc: 0.983 - 27s 22ms/step - loss: 0.0806 - acc: 0.9817 - val_loss: 0.0694 - val_acc: 0.9710\n",
      "Epoch 7/20\n",
      "1205/1205 [==============================] - ETA: 22s - loss: 0.0775 - acc: 0.98 - ETA: 20s - loss: 0.0494 - acc: 0.99 - ETA: 19s - loss: 0.0428 - acc: 0.98 - ETA: 19s - loss: 0.0532 - acc: 0.98 - ETA: 21s - loss: 0.0476 - acc: 0.98 - ETA: 22s - loss: 0.0573 - acc: 0.97 - ETA: 21s - loss: 0.0668 - acc: 0.97 - ETA: 20s - loss: 0.0702 - acc: 0.97 - ETA: 19s - loss: 0.0690 - acc: 0.97 - ETA: 18s - loss: 0.0638 - acc: 0.97 - ETA: 16s - loss: 0.0648 - acc: 0.98 - ETA: 14s - loss: 0.0782 - acc: 0.97 - ETA: 12s - loss: 0.0774 - acc: 0.97 - ETA: 9s - loss: 0.0751 - acc: 0.9788 - ETA: 7s - loss: 0.0744 - acc: 0.979 - ETA: 5s - loss: 0.0735 - acc: 0.979 - ETA: 3s - loss: 0.0786 - acc: 0.975 - ETA: 1s - loss: 0.0800 - acc: 0.974 - 38s 32ms/step - loss: 0.0773 - acc: 0.9751 - val_loss: 0.0415 - val_acc: 0.9884\n",
      "Epoch 8/20\n",
      "1205/1205 [==============================] - ETA: 39s - loss: 0.0684 - acc: 0.98 - ETA: 39s - loss: 0.0599 - acc: 0.98 - ETA: 38s - loss: 0.0504 - acc: 0.98 - ETA: 36s - loss: 0.0454 - acc: 0.99 - ETA: 34s - loss: 0.0396 - acc: 0.99 - ETA: 32s - loss: 0.0375 - acc: 0.99 - ETA: 29s - loss: 0.0419 - acc: 0.99 - ETA: 27s - loss: 0.0470 - acc: 0.98 - ETA: 24s - loss: 0.0441 - acc: 0.98 - ETA: 22s - loss: 0.0409 - acc: 0.99 - ETA: 19s - loss: 0.0488 - acc: 0.98 - ETA: 17s - loss: 0.0816 - acc: 0.98 - ETA: 14s - loss: 0.0770 - acc: 0.98 - ETA: 12s - loss: 0.0732 - acc: 0.98 - ETA: 9s - loss: 0.0726 - acc: 0.9812 - ETA: 7s - loss: 0.0707 - acc: 0.981 - ETA: 4s - loss: 0.0753 - acc: 0.979 - ETA: 2s - loss: 0.0896 - acc: 0.976 - 54s 44ms/step - loss: 0.0866 - acc: 0.9776 - val_loss: 0.0412 - val_acc: 0.9884\n",
      "Epoch 9/20\n",
      "1205/1205 [==============================] - ETA: 45s - loss: 0.0750 - acc: 0.96 - ETA: 43s - loss: 0.0612 - acc: 0.98 - ETA: 40s - loss: 0.0477 - acc: 0.98 - ETA: 38s - loss: 0.0396 - acc: 0.99 - ETA: 35s - loss: 0.0422 - acc: 0.99 - ETA: 32s - loss: 0.0492 - acc: 0.99 - ETA: 30s - loss: 0.0572 - acc: 0.99 - ETA: 27s - loss: 0.0605 - acc: 0.98 - ETA: 25s - loss: 0.0643 - acc: 0.98 - ETA: 22s - loss: 0.0620 - acc: 0.98 - ETA: 20s - loss: 0.0686 - acc: 0.98 - ETA: 17s - loss: 0.0926 - acc: 0.97 - ETA: 15s - loss: 0.0915 - acc: 0.97 - ETA: 12s - loss: 0.0947 - acc: 0.97 - ETA: 9s - loss: 0.1048 - acc: 0.9708 - ETA: 7s - loss: 0.1022 - acc: 0.971 - ETA: 4s - loss: 0.1003 - acc: 0.972 - ETA: 2s - loss: 0.0986 - acc: 0.973 - 54s 45ms/step - loss: 0.0985 - acc: 0.9718 - val_loss: 0.0879 - val_acc: 0.9768\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205/1205 [==============================] - ETA: 45s - loss: 0.1582 - acc: 0.95 - ETA: 48s - loss: 0.1511 - acc: 0.94 - ETA: 37s - loss: 0.1449 - acc: 0.94 - ETA: 31s - loss: 0.1650 - acc: 0.94 - ETA: 27s - loss: 0.1464 - acc: 0.95 - ETA: 23s - loss: 0.1318 - acc: 0.96 - ETA: 21s - loss: 0.1273 - acc: 0.96 - ETA: 18s - loss: 0.1154 - acc: 0.96 - ETA: 16s - loss: 0.1047 - acc: 0.97 - ETA: 14s - loss: 0.0966 - acc: 0.97 - ETA: 13s - loss: 0.0947 - acc: 0.97 - ETA: 12s - loss: 0.1101 - acc: 0.97 - ETA: 10s - loss: 0.1036 - acc: 0.97 - ETA: 9s - loss: 0.1080 - acc: 0.9732 - ETA: 7s - loss: 0.1158 - acc: 0.971 - ETA: 5s - loss: 0.1118 - acc: 0.972 - ETA: 3s - loss: 0.1085 - acc: 0.973 - ETA: 1s - loss: 0.1058 - acc: 0.974 - 43s 36ms/step - loss: 0.1045 - acc: 0.9734 - val_loss: 0.0469 - val_acc: 0.9923\n",
      "Epoch 11/20\n",
      "1205/1205 [==============================] - ETA: 23s - loss: 0.0352 - acc: 1.00 - ETA: 21s - loss: 0.0401 - acc: 1.00 - ETA: 20s - loss: 0.0459 - acc: 0.98 - ETA: 19s - loss: 0.0536 - acc: 0.99 - ETA: 18s - loss: 0.0543 - acc: 0.99 - ETA: 16s - loss: 0.0538 - acc: 0.98 - ETA: 15s - loss: 0.0520 - acc: 0.99 - ETA: 14s - loss: 0.0478 - acc: 0.99 - ETA: 12s - loss: 0.0444 - acc: 0.99 - ETA: 11s - loss: 0.0411 - acc: 0.99 - ETA: 10s - loss: 0.0412 - acc: 0.99 - ETA: 8s - loss: 0.0469 - acc: 0.9896 - ETA: 7s - loss: 0.0444 - acc: 0.990 - ETA: 6s - loss: 0.0454 - acc: 0.990 - ETA: 4s - loss: 0.0477 - acc: 0.988 - ETA: 3s - loss: 0.0494 - acc: 0.988 - ETA: 2s - loss: 0.0584 - acc: 0.986 - ETA: 1s - loss: 0.0565 - acc: 0.987 - 28s 23ms/step - loss: 0.0558 - acc: 0.9867 - val_loss: 0.0332 - val_acc: 0.9884\n",
      "Epoch 12/20\n",
      "1205/1205 [==============================] - ETA: 22s - loss: 0.0205 - acc: 0.98 - ETA: 21s - loss: 0.0150 - acc: 0.99 - ETA: 20s - loss: 0.0217 - acc: 0.98 - ETA: 19s - loss: 0.0226 - acc: 0.99 - ETA: 17s - loss: 0.0205 - acc: 0.99 - ETA: 16s - loss: 0.0218 - acc: 0.99 - ETA: 15s - loss: 0.0216 - acc: 0.99 - ETA: 14s - loss: 0.0213 - acc: 0.99 - ETA: 12s - loss: 0.0217 - acc: 0.99 - ETA: 11s - loss: 0.0208 - acc: 0.99 - ETA: 10s - loss: 0.0207 - acc: 0.99 - ETA: 8s - loss: 0.0437 - acc: 0.9948 - ETA: 7s - loss: 0.0413 - acc: 0.995 - ETA: 6s - loss: 0.0407 - acc: 0.993 - ETA: 5s - loss: 0.0415 - acc: 0.991 - ETA: 3s - loss: 0.0419 - acc: 0.991 - ETA: 2s - loss: 0.0423 - acc: 0.991 - ETA: 1s - loss: 0.0414 - acc: 0.992 - 28s 24ms/step - loss: 0.0401 - acc: 0.9925 - val_loss: 0.0283 - val_acc: 0.9903\n",
      "Epoch 13/20\n",
      "1205/1205 [==============================] - ETA: 22s - loss: 0.0156 - acc: 1.00 - ETA: 21s - loss: 0.0243 - acc: 0.99 - ETA: 20s - loss: 0.0243 - acc: 0.99 - ETA: 19s - loss: 0.0231 - acc: 0.99 - ETA: 18s - loss: 0.0202 - acc: 0.99 - ETA: 19s - loss: 0.0220 - acc: 0.99 - ETA: 19s - loss: 0.0229 - acc: 0.99 - ETA: 19s - loss: 0.0211 - acc: 0.99 - ETA: 18s - loss: 0.0213 - acc: 0.99 - ETA: 17s - loss: 0.0202 - acc: 0.99 - ETA: 15s - loss: 0.0206 - acc: 0.99 - ETA: 14s - loss: 0.0309 - acc: 0.99 - ETA: 12s - loss: 0.0295 - acc: 0.99 - ETA: 10s - loss: 0.0302 - acc: 0.99 - ETA: 8s - loss: 0.0314 - acc: 0.9917 - ETA: 6s - loss: 0.0314 - acc: 0.991 - ETA: 3s - loss: 0.0307 - acc: 0.991 - ETA: 1s - loss: 0.0312 - acc: 0.991 - 41s 34ms/step - loss: 0.0307 - acc: 0.9917 - val_loss: 0.0273 - val_acc: 0.9903\n",
      "Epoch 14/20\n",
      "1205/1205 [==============================] - ETA: 22s - loss: 0.0129 - acc: 1.00 - ETA: 21s - loss: 0.0100 - acc: 1.00 - ETA: 20s - loss: 0.0119 - acc: 1.00 - ETA: 19s - loss: 0.0175 - acc: 1.00 - ETA: 17s - loss: 0.0170 - acc: 1.00 - ETA: 16s - loss: 0.0155 - acc: 1.00 - ETA: 15s - loss: 0.0232 - acc: 0.99 - ETA: 14s - loss: 0.0217 - acc: 0.99 - ETA: 12s - loss: 0.0201 - acc: 0.99 - ETA: 11s - loss: 0.0182 - acc: 0.99 - ETA: 10s - loss: 0.0174 - acc: 0.99 - ETA: 8s - loss: 0.0426 - acc: 0.9935 - ETA: 7s - loss: 0.0405 - acc: 0.994 - ETA: 6s - loss: 0.0426 - acc: 0.993 - ETA: 4s - loss: 0.0459 - acc: 0.992 - ETA: 3s - loss: 0.0456 - acc: 0.992 - ETA: 2s - loss: 0.0436 - acc: 0.992 - ETA: 1s - loss: 0.0421 - acc: 0.993 - 28s 23ms/step - loss: 0.0409 - acc: 0.9934 - val_loss: 0.0286 - val_acc: 0.9923\n",
      "Epoch 15/20\n",
      "1205/1205 [==============================] - ETA: 23s - loss: 0.0629 - acc: 0.98 - ETA: 21s - loss: 0.0551 - acc: 0.98 - ETA: 20s - loss: 0.0393 - acc: 0.98 - ETA: 19s - loss: 0.0354 - acc: 0.98 - ETA: 17s - loss: 0.0311 - acc: 0.99 - ETA: 16s - loss: 0.0324 - acc: 0.98 - ETA: 15s - loss: 0.0305 - acc: 0.99 - ETA: 15s - loss: 0.0311 - acc: 0.99 - ETA: 15s - loss: 0.0292 - acc: 0.99 - ETA: 14s - loss: 0.0268 - acc: 0.99 - ETA: 13s - loss: 0.0256 - acc: 0.99 - ETA: 12s - loss: 0.0433 - acc: 0.98 - ETA: 11s - loss: 0.0410 - acc: 0.99 - ETA: 9s - loss: 0.0387 - acc: 0.9911 - ETA: 7s - loss: 0.0408 - acc: 0.990 - ETA: 5s - loss: 0.0397 - acc: 0.990 - ETA: 3s - loss: 0.0395 - acc: 0.989 - ETA: 1s - loss: 0.0383 - acc: 0.989 - 45s 38ms/step - loss: 0.0369 - acc: 0.9900 - val_loss: 0.0296 - val_acc: 0.9942\n",
      "Epoch 16/20\n",
      "1205/1205 [==============================] - ETA: 46s - loss: 0.0301 - acc: 1.00 - ETA: 43s - loss: 0.0274 - acc: 1.00 - ETA: 40s - loss: 0.0307 - acc: 0.99 - ETA: 38s - loss: 0.0280 - acc: 0.99 - ETA: 35s - loss: 0.0292 - acc: 0.99 - ETA: 33s - loss: 0.0289 - acc: 0.99 - ETA: 30s - loss: 0.0258 - acc: 0.99 - ETA: 28s - loss: 0.0235 - acc: 0.99 - ETA: 25s - loss: 0.0213 - acc: 0.99 - ETA: 22s - loss: 0.0198 - acc: 0.99 - ETA: 20s - loss: 0.0196 - acc: 0.99 - ETA: 17s - loss: 0.0293 - acc: 0.99 - ETA: 15s - loss: 0.0288 - acc: 0.99 - ETA: 12s - loss: 0.0274 - acc: 0.99 - ETA: 9s - loss: 0.0283 - acc: 0.9927 - ETA: 7s - loss: 0.0284 - acc: 0.992 - ETA: 4s - loss: 0.0291 - acc: 0.991 - ETA: 2s - loss: 0.0283 - acc: 0.992 - 54s 45ms/step - loss: 0.0275 - acc: 0.9925 - val_loss: 0.0238 - val_acc: 0.9942\n",
      "Epoch 17/20\n",
      "1205/1205 [==============================] - ETA: 45s - loss: 0.0118 - acc: 1.00 - ETA: 43s - loss: 0.0210 - acc: 0.99 - ETA: 40s - loss: 0.0247 - acc: 0.98 - ETA: 38s - loss: 0.0214 - acc: 0.99 - ETA: 35s - loss: 0.0198 - acc: 0.99 - ETA: 32s - loss: 0.0173 - acc: 0.99 - ETA: 30s - loss: 0.0175 - acc: 0.99 - ETA: 27s - loss: 0.0157 - acc: 0.99 - ETA: 25s - loss: 0.0143 - acc: 0.99 - ETA: 22s - loss: 0.0136 - acc: 0.99 - ETA: 20s - loss: 0.0137 - acc: 0.99 - ETA: 17s - loss: 0.0307 - acc: 0.99 - ETA: 14s - loss: 0.0293 - acc: 0.99 - ETA: 12s - loss: 0.0286 - acc: 0.99 - ETA: 9s - loss: 0.0315 - acc: 0.9927 - ETA: 7s - loss: 0.0317 - acc: 0.992 - ETA: 4s - loss: 0.0320 - acc: 0.991 - ETA: 2s - loss: 0.0315 - acc: 0.992 - 54s 45ms/step - loss: 0.0303 - acc: 0.9925 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "Epoch 18/20\n",
      "1205/1205 [==============================] - ETA: 45s - loss: 0.0203 - acc: 1.00 - ETA: 43s - loss: 0.0185 - acc: 1.00 - ETA: 40s - loss: 0.0163 - acc: 1.00 - ETA: 38s - loss: 0.0155 - acc: 0.99 - ETA: 35s - loss: 0.0161 - acc: 0.99 - ETA: 33s - loss: 0.0167 - acc: 0.99 - ETA: 30s - loss: 0.0149 - acc: 0.99 - ETA: 27s - loss: 0.0138 - acc: 0.99 - ETA: 25s - loss: 0.0132 - acc: 0.99 - ETA: 22s - loss: 0.0121 - acc: 0.99 - ETA: 20s - loss: 0.0124 - acc: 0.99 - ETA: 17s - loss: 0.0210 - acc: 0.99 - ETA: 15s - loss: 0.0208 - acc: 0.99 - ETA: 12s - loss: 0.0202 - acc: 0.99 - ETA: 9s - loss: 0.0248 - acc: 0.9958 - ETA: 7s - loss: 0.0240 - acc: 0.995 - ETA: 4s - loss: 0.0230 - acc: 0.995 - ETA: 2s - loss: 0.0228 - acc: 0.995 - 54s 45ms/step - loss: 0.0223 - acc: 0.9959 - val_loss: 0.0315 - val_acc: 0.9884\n",
      "Epoch 19/20\n",
      "1205/1205 [==============================] - ETA: 45s - loss: 0.0101 - acc: 1.00 - ETA: 43s - loss: 0.0058 - acc: 1.00 - ETA: 40s - loss: 0.0076 - acc: 1.00 - ETA: 38s - loss: 0.0096 - acc: 1.00 - ETA: 35s - loss: 0.0097 - acc: 1.00 - ETA: 33s - loss: 0.0117 - acc: 0.99 - ETA: 30s - loss: 0.0229 - acc: 0.99 - ETA: 28s - loss: 0.0209 - acc: 0.99 - ETA: 24s - loss: 0.0206 - acc: 0.99 - ETA: 20s - loss: 0.0198 - acc: 0.99 - ETA: 17s - loss: 0.0183 - acc: 0.99 - ETA: 14s - loss: 0.0240 - acc: 0.99 - ETA: 12s - loss: 0.0225 - acc: 0.99 - ETA: 9s - loss: 0.0217 - acc: 0.9944 - ETA: 7s - loss: 0.0251 - acc: 0.993 - ETA: 5s - loss: 0.0241 - acc: 0.994 - ETA: 3s - loss: 0.0234 - acc: 0.994 - ETA: 1s - loss: 0.0263 - acc: 0.993 - 38s 32ms/step - loss: 0.0254 - acc: 0.9942 - val_loss: 0.0253 - val_acc: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "1205/1205 [==============================] - ETA: 23s - loss: 0.0102 - acc: 1.00 - ETA: 22s - loss: 0.0137 - acc: 1.00 - ETA: 20s - loss: 0.0117 - acc: 1.00 - ETA: 19s - loss: 0.0096 - acc: 1.00 - ETA: 18s - loss: 0.0113 - acc: 0.99 - ETA: 16s - loss: 0.0123 - acc: 0.99 - ETA: 15s - loss: 0.0151 - acc: 0.99 - ETA: 14s - loss: 0.0145 - acc: 0.99 - ETA: 12s - loss: 0.0130 - acc: 0.99 - ETA: 11s - loss: 0.0133 - acc: 0.99 - ETA: 10s - loss: 0.0139 - acc: 0.99 - ETA: 9s - loss: 0.0348 - acc: 0.9922 - ETA: 8s - loss: 0.0325 - acc: 0.992 - ETA: 7s - loss: 0.0306 - acc: 0.993 - ETA: 6s - loss: 0.0325 - acc: 0.992 - ETA: 4s - loss: 0.0326 - acc: 0.992 - ETA: 3s - loss: 0.0320 - acc: 0.992 - ETA: 1s - loss: 0.0316 - acc: 0.992 - 38s 31ms/step - loss: 0.0309 - acc: 0.9925 - val_loss: 0.0438 - val_acc: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dc653f9b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=64,verbose=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 99.25%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on train data\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 98.65%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on validation data\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have prepared the test data to check the accuracy. The name and target values are stored in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the test data\n",
    "test_images = r\"C:\\\\Users\\\\hp\\\\Downloads\\\\images_upright\\\\query\\\\night\\\\milestone\\\\Renamed\\\\\"\n",
    "test_df = pd.read_csv('C:\\\\Users\\\\hp\\\\Downloads\\\\images_upright\\\\query\\\\night\\\\milestone\\\\test_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 472/472 [00:21<00:00, 21.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#Converting image data into array\n",
    "test_image = []\n",
    "for i in tqdm(range(int((test_df.shape[0])))):\n",
    "    img = image.load_img(test_images+str(test_df['image_names'][i]),target_size=(300,300))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    test_image.append(img)\n",
    "X = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for day and night\n",
    "proba = model.predict(X)\n",
    "y_classes = proba.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending the predicted classes to the test dataframe\n",
    "test_df ['predicted'] = y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>104.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>107.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>109.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>110.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>111.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>112.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>113.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>114.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>115.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>116.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>117.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>119.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>120.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>121.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>122.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>124.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>125.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>126.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>72.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>73.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>74.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>75.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>76.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>77.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>78.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>79.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>80.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>81.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>82.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>83.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>84.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>85.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>86.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>87.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>88.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>90.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>91.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>92.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>93.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>94.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>95.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>96.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>97.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>98.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>99.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_names  target  predicted\n",
       "0        10.jpg       1          1\n",
       "1       100.jpg       1          1\n",
       "2       101.jpg       0          0\n",
       "3       102.jpg       1          1\n",
       "4       103.jpg       0          0\n",
       "5       104.jpg       1          1\n",
       "6       105.jpg       0          1\n",
       "7       106.jpg       1          1\n",
       "8       107.jpg       0          0\n",
       "9       108.jpg       1          1\n",
       "10      109.jpg       0          0\n",
       "11       11.jpg       0          0\n",
       "12      110.jpg       1          1\n",
       "13      111.jpg       0          0\n",
       "14      112.jpg       1          1\n",
       "15      113.jpg       0          0\n",
       "16      114.jpg       1          1\n",
       "17      115.jpg       0          1\n",
       "18      116.jpg       1          1\n",
       "19      117.jpg       0          0\n",
       "20      118.jpg       1          1\n",
       "21      119.jpg       0          1\n",
       "22       12.jpg       1          1\n",
       "23      120.jpg       1          1\n",
       "24      121.jpg       0          1\n",
       "25      122.jpg       1          1\n",
       "26      123.jpg       0          0\n",
       "27      124.jpg       1          1\n",
       "28      125.jpg       0          1\n",
       "29      126.jpg       1          1\n",
       "..          ...     ...        ...\n",
       "442      72.jpg       1          1\n",
       "443      73.jpg       0          1\n",
       "444      74.jpg       1          1\n",
       "445      75.jpg       0          0\n",
       "446      76.jpg       1          1\n",
       "447      77.jpg       0          0\n",
       "448      78.jpg       1          1\n",
       "449      79.jpg       0          0\n",
       "450       8.jpg       1          1\n",
       "451      80.jpg       1          1\n",
       "452      81.jpg       0          0\n",
       "453      82.jpg       1          1\n",
       "454      83.jpg       0          0\n",
       "455      84.jpg       1          1\n",
       "456      85.jpg       0          0\n",
       "457      86.jpg       1          1\n",
       "458      87.jpg       0          0\n",
       "459      88.jpg       1          1\n",
       "460      89.jpg       0          1\n",
       "461       9.jpg       0          0\n",
       "462      90.jpg       1          1\n",
       "463      91.jpg       0          1\n",
       "464      92.jpg       1          1\n",
       "465      93.jpg       0          0\n",
       "466      94.jpg       1          1\n",
       "467      95.jpg       0          1\n",
       "468      96.jpg       1          1\n",
       "469      97.jpg       0          1\n",
       "470      98.jpg       1          1\n",
       "471      99.jpg       0          0\n",
       "\n",
       "[472 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the values in df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: : 75.42%\n",
      "F1 Score: : 73.41%\n",
      "Precision Score: : 74.67%\n",
      "Recall Score: : 83.84%\n"
     ]
    }
   ],
   "source": [
    "#Checking model performance with different metrics\n",
    "print(\"%s: %.2f%%\" % (\"Accuracy: \",accuracy_score(test_df['target'], y_classes)*100))\n",
    "print(\"%s: %.2f%%\" % (\"F1 Score: \",f1_score(test_df['target'], y_classes, average=\"macro\")*100))\n",
    "print(\"%s: %.2f%%\" % (\"Precision Score: \",precision_score(test_df['target'], y_classes, average=\"macro\")*100))\n",
    "print(\"%s: %.2f%%\" % (\"Recall Score: \",recall_score(test_df['target'], y_classes, average=\"macro\")*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21e52c0eeb8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAFpCAYAAACs3TNfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFh5JREFUeJzt3Xuwn3V9J/D3JwmgXIoBJATCRTFeEEZUinYZtetlveCIXUpXXCvr0kk74nbV2urWVha3Wtcd7ZSZapsWFOqCstO6UqVaJ+MOu94gKouwgEaNEMJFLmIICrl89w9O6AEOOQkn5zzn++T1mnkmv/P9Pef3fJ8ZQt7z+X6e769aawEAGNKCoScAACCQAACDE0gAgMEJJADA4AQSAGBwAgkAMDiBBAAYnEACAAxOIAEABieQAACDWzTbF3jiEafbmx4G8PLz3jr0FGC39Q+veFHN5fVm+m/tz2+8eE7nO5VZDyQAwOyq6n/Bo/87AAC6p0ICAJ2rEdQXBBIA6NwYlmwEEgDo3BgCSf93AAB0T4UEADpXNfhTuzMmkABA9/pf8BBIAKBzY+ghEUgAoHNjCCT93wEA0D0VEgDonI3RAIDBjWHJRiABgM4JJADA4MYQSPq/AwCgeyokANC5ip1aAYCBjWHJRiABgM6NIZD0fwcAQPdUSACgc2OokAgkANA9gQQAGJgKCQAwuDEEkv7vAADongoJAHTOt/0CAIMbw5KNQAIAnauydTwAMLAxVEj6vwMAoHsqJADQOU2tAMDgxrBkI5AAQOfGEEj6vwMAoHsqJADQOT0kAMDwRrBkI5AAQOfG0EMikABA58awU2v/kQoA6J4KCQB0TlMrADA4PSQAwPBG0EMikABA7/ovkIzhFgCA3qmQAEDvLNkAAIMTSACAwY2gAWMEtwAA9E6FBAA61yzZAACD6z+PCCQA0L0F/ScSgQQAejeCJRtNrQDAdlXV4VX1laq6rqqurar/ODF+QFV9uaq+P/Hn4onxqqpzq2pNVV1dVc+b7hoCCQD0rmZ4TG9zkt9rrT0ryQuTnFVVxyR5T5JVrbXlSVZN/Jwkr06yfOJYkeTj011AIAGA3i2omR3TaK3d0lr79sTrDUmuS3JYklOSXDBx2gVJXj/x+pQkF7YHfSPJk6pq6fauoYcEAHo3hz0kVXVUkucm+WaSJa21W5IHQ0tVHTxx2mFJbpr0a+smxm55rM9VIQGA3s1wyaaqVlTV6knHiikvU7Vvkr9L8vbW2s+mmdEjte3dggoJAOzmWmsrk6zc3jlVtUceDCP/vbX29xPDt1XV0onqyNIkt0+Mr0ty+KRfX5Zk/fY+X4UEAHo3yz0kVVVJzktyXWvto5PeujTJGROvz0jyuUnjb5542uaFSe7ZtrTzWFRIAKB3s99CclKS30zy3aq6amLsD5N8KMklVXVmkhuTnDbx3mVJXpNkTZL7krxlugsIJADQudn+LpvW2v/JY8eel01xfkty1s5cw5INADA4FRIA6J3vsgEABtd/HhFIAKB7I/hyPYEEAHo3giUbTa0AwOBUSACgd/0XSAQSAOieHhIAYHACCQAwuBF0hI7gFgCA3qmQAEDvLNkAAIPrP48IJADQuzaCjdEEkt3YsqUH5G/+7K1Z8uQnZWtrOf+iVfmL87/40PtvX3Fy/vSP3pRlz1mRO+/ekNe+4vl537t+I1u3bs3mLVvzB+dcmK9decOAdwD9+t1jlueXn3xA7nlgU9729W8nSU46+KC88egjsmyfvfN7V1yVNT+796Hzj9p375z1rOXZe9HCbG3JO6/4TjZtbUNNH3Y5gWQ3tnnL1rznTz6Vq65Zm333eUK+9oUPZtX//m6u//7NWbb0gLz0RcflxnU/eej8r3z1mnz+y99Kkhz7zCPyqY/9bo5/6buGmj50bdX62/KFm9bnHcc+46GxH2/cmA/+3+ty1rOe9rBzF1TyzmOfmY9ec0PW3rsx++2xKFuEESYbQQ/JtE/ZVNUzq+rdVXVuVf35xOtnzcXkmF233v7TXHXN2iTJvRt/kevX3JxDDzkgSfLhs9+c937worRJ/8/beN/9D73eZ++9HvYesHOu/enPsmHT5oeNrdv489x8388fde5zD1yctfduzNp7NyZJNmzanK1zMku6UTM85oHtVkiq6t1JTk/y6SRXTAwvS3JxVX26tfahWZ4fc+SIZQfl+GcflSu/syYnv+L5WX/rXfnudTc+6rzXvfKEvP/db8iTD9o///rffXiAmcLu57C9n5i0lnOee2z233OPXH7rT/L3P1439LSYT3aDHpIzkzy7tbZp8mBVfTTJtUkEkhHYZ++9cvFfvSO/f86F2bx5S979ttfntW/64JTnXvql1bn0S6tz0onPzPvedVpOfuPU5wG7zsKqHLN4/7zzm9/J/Vu25k+ef1zWbLg3V9/106GnxnyxGyzZbE1y6BTjSyfem1JVraiq1VW1evO9a2YyP2bZokULc/FfvSOf+exX87kvXpmnHrkkRx7+5Fzxxf+a6796bg5bekC+ftkHs+TJ+z/s9756xfV56hFLcuDi/QaaOew+7vjFA7nm7nvys02bc//WrVl9x105er99hp4W7FLTVUjenmRVVX0/yU0TY0ckeVqStz3WL7XWViZZmSRPPOJ0nQbz2F/+txW5Yc36nPs3lyVJrr3hphz5vN956P3rv3puTnrte3Pn3Rvy1COX5Ic/vi1JcvyxR2XPPRflzrs3DDJv2J18+867c+pRy7LXggXZ1Lbm2MX753M33jz0tJhP+i+QbD+QtNa+WFVPT3JiksPy4C2vS3Jla23LHMyPWfQvfvkZ+benvjjfve7GfOMf/zRJcvaHP5MvfeWqKc//tdecmDee+uJs2rQ5v/jFA/nNs86dy+nCqLzruGfkuMVPyi/tsSifeNGJuegHP86GTZvz2888OvvvuUfed/yz86MNG3P2d67Jxs2b8z9/vC4ffcHxaUlW33FXVt9x99C3wHwygh6SarP8qIQKCQzj5ee9degpwG7rH17xojlNCEef+T9m9G/tD847bfBE48v1AIDB2RgNADrXBq9vzJxAAgC9G0EPiUACAL0bwT4kAgkA9G4EFRJNrQDA4FRIAKB3IygvCCQA0Ds9JADA4EbQQyKQAEDn2ggqJCNYdQIAeqdCAgC9G0F5QSABgN7pIQEABqeHBABg5lRIAKB3lmwAgMH1n0cEEgDoXVMhAQAGN4JAoqkVABicCgkA9G4Ej/0KJADQuxGsdwgkANA7FRIAYHCaWgEAZk6FBAB6N4IKiUACAJ1rekgAgMGNoAFjBLcAAPROhQQAemfJBgAYnKZWAGBwAgkAMLj+84imVgBgeCokANC5ZskGABjcCJ6ysWQDAL1bUDM7plFV51fV7VV1zaSx/1xVN1fVVRPHaya995+qak1V3VBVr9yhW3hcNw4AzB81w2N6n0zyqinG/6y1dvzEcVmSVNUxSd6Q5NkTv/Oxqlo43QUEEgBgu1prlye5awdPPyXJp1tr97fWfpRkTZITp/slgQQAOrdgwcyOqlpRVasnHSt28NJvq6qrJ5Z0Fk+MHZbkpknnrJsY2/497OQ9AwDzTNXMjtbaytbaCZOOlTtw2Y8nOTrJ8UluSfKRbdOZ4tw23Yd5ygYAOjfEQzattdv++fr110k+P/HjuiSHTzp1WZL1032eCgkAsNOqaumkH38tybYncC5N8oaq2quqnpJkeZIrpvs8FRIA6FzNcomkqi5O8qtJDqqqdUnOTvKrVXV8HlyOWZvkt5OktXZtVV2S5P8l2ZzkrNbalumuIZAAQOdme8mmtXb6FMPnbef8DyT5wM5cQyABgM6NYKNWgQQAelcj6AgdwS0AAL1TIQGAzlmyAQAGtwPfjzfvCSQA0DkVEgBgcGMIJJpaAYDBqZAAQOdme6fWuSCQAEDnxrAPiUACAJ0bQYFEDwkAMDwVEgDo3BgqJAIJAHROIAEABmenVgBgcGOokGhqBQAGp0ICAJ0bQ4VEIAGAztUImkgEEgDonAoJADC4MQQSTa0AwOBUSACgc2OokAgkANC5EfS0CiQA0LsxVEj0kAAAg1MhAYDO1QjKCwIJAHRuDEs2AgkAdK5GkEgEEgDo3AjyiKZWAGB4KiQA0LkxVEhmPZD8/MZzZvsSwBROXXXb0FMA5ohAAgAMzk6tAMDgxhBINLUCAINTIQGAzi2oNvQUZkwgAYDOjWHJRiABgM6Nof9iDPcAAHROhQQAOqeHBAAYnB4SAGBwY+i/EEgAoHNjqJCMIVQBAJ1TIQGAzpWmVgBgaGNYshFIAKBzY+i/GMM9AACdUyEBgM7ZGA0AGJweEgBgcGPovxBIAKBzY6iQjCFUAQCdUyEBgM5pagUABjeGJRuBBAA6N4b+C4EEADo3hiWbMYQqAGAWVdX5VXV7VV0zaeyAqvpyVX1/4s/FE+NVVedW1Zqqurqqnrcj1xBIAKBzC2pmxw74ZJJXPWLsPUlWtdaWJ1k18XOSvDrJ8oljRZKP79A97NA0AIB5a7YDSWvt8iR3PWL4lCQXTLy+IMnrJ41f2B70jSRPqqql011DDwkAdG6g6sKS1totSdJau6WqDp4YPyzJTZPOWzcxdsv2PkyFBAB2c1W1oqpWTzpWzOTjphibtutWhQQAOjfTp2xaayuTrNzJX7utqpZOVEeWJrl9YnxdksMnnbcsyfrpPkyFBAA6NwdNrVO5NMkZE6/PSPK5SeNvnnja5oVJ7tm2tLM9KiQA0LnZri5U1cVJfjXJQVW1LsnZST6U5JKqOjPJjUlOmzj9siSvSbImyX1J3rIj1xBIAKBzs711fGvt9Md462VTnNuSnLWz17BkAwAMToUEADpXI9g6XiABgM75tl8AYHBj6L8QSACgc77tFwBgF1AhAYDO6SEBAAYnkAAAg1s49AR2AT0kAMDgVEgAoHNjeMpGIAGAzukhAQAGJ5AAAINbOIJAoqkVABicCgkAdM6SDQAwOE/ZAACDUyEBAAZnp1YAgF1AhQQAOmfJBgAYnKZWAGBwNkYDANgFVEgAoHN6SACAwQkkAMDgBBIAYHALR/CUjaZWAGBwKiQA0LkxVBcEEgDonB4SAGBwAgkAMDhNrQAAu4AKCQB0zpINADA4gQQAGNwYAokeEgBgcCokANC5hSOokAgkANC5BSN47FcgAYDOjaH/QiABgM6NoalVIGFKl1/+rXzgA3+drVu35rTTXpEVK04bekowKuv+9hPZ8N2rs2i//bL8j9+fJLnn26tz+xcuzf233pKj/+C9eeKRRyVJ7lv7w6y/6G8f/MXWcvDJr8svHf+8gWYOs0Mg4VG2bNmS97//L/OJT/yXLFlyYH7919+Zl770BXna044YemowGotfeFIOfMlLs+6C8x4a22vpoTlixVtz80UXPuzcJxx6WI5+9x+lFi7Mpnt+mjUfOCf7Hfec1MKFcz1t5ilNrYzS1Vd/P0ceuTSHH35IkuTkk1+cVau+KZDALrTP8qfngTvveNjYE5YeOuW5C/bc66HXbdOmZAT/+LBraWpllG677c4ccshBD/28ZMmBufrq7w04I+C+H/0wN3/qk9l0151ZdsaZqiM8zG7dQ1JVb2mtfWJXTob5obVHJ+2qEfzXDh3b+ylPzfI/fn9+ccv63Hzh+dn32cdlwR57DD0t5okxBJKZPCl0zmO9UVUrqmp1Va1eufIzM7gEQzjkkINy663/XEq+7bY7c/DBBww4I2CbJyw9NAv23Cv3r7956KnALrXdCklVXf1YbyVZ8li/11pbmWTlgz99r/+Frd3Mccctz9q163PTTbdmyZID84UvXJ6PfORdQ08LdlsP3PGT7LH4gNTChXngzjtz/+23Zo8DDxx6Wswju8M+JEuSvDLJ3Y8YryRfm5UZMbhFixbmfe/7nfzWb52dLVu25tRTX57ly48celowKjedvzIbv3dDNt97b67/w9/PwSe/Lov22SfrL7k4W+7dkLUf+/M8cdkROeo/vCMbf7Amd/zTPz7YN1KVQ//Nm7Jo3/2GvgXmkTGsqk8XSD6fZN/W2lWPfKOq/teszIh54SUvOSEveckJQ08DRuvwf79iyvGp9hdZ/IJfyeIX/MpsT4mOjSCPbD+QtNbO3M57b9z10wEAdkce+wWAzu0OSzYAwDy3OzS1AgDzXNmpFQAY2ghWbEZR5QEAOqdCAgCd09QKAAxuLvJIVa1NsiHJliSbW2snVNUBST6T5Kgka5P8RmvtkZup7hBLNgDQuQU1s2Mn/MvW2vGttW07Z74nyarW2vIkqyZ+fnz38Hh/EQCYH2qGxwyckuSCidcXJHn94/0ggQQA2BEtyT9V1beqatt3Hyxprd2SJBN/Hvx4P1wPCQB0bqZNrRMBY/IXLK1sra18xGkntdbWV9XBSb5cVdfP7KoPJ5AAQOdm2tQ6ET4eGUAeec76iT9vr6rPJjkxyW1VtbS1dktVLU1y++OdgyUbAOjcbPeQVNU+VbXfttdJ/lWSa5JcmuSMidPOSPK5x3sPKiQAwHSWJPlsPbg2tCjJRa21L1bVlUkuqaozk9yY5LTHewGBBAA6t5OP7u601toPkzxnivE7k7xsV1xDIAGAzo1go1aBBAB659t+AYDBjaFC4ikbAGBwKiQA0Dnf9gsADG4Myx0CCQB0bgwVkjGEKgCgcyokANC5ERRIBBIA6N0YlmwEEgDo3AjyiEACAL2b7e+ymQuaWgGAwamQAEDnRlAgEUgAoHe+XA8AGJwKCQAwuDE89qupFQAYnAoJAHRuBAUSgQQAejeG5Q6BBAA6p4cEAGAXUCEBgO71XyIRSACgcyWQAABDq+q/A0MgAYDu9V8h6T9SAQDdUyEBgM7pIQEA5gGBBAAYmKZWAGAe6L9C0n+kAgC6p0ICAJ3T1AoADE4gAQDmgf47MPq/AwCgeyokANC5Kks2AMDgBBIAYGCaWgGAeaD/ltD+7wAA6J4KCQB0zpINADA4T9kAAPOAQAIADKxG0BLa/x0AAN1TIQGA7lmyAQAGpqkVAJgH+g8kekgAgMGpkABA58bwlI1AAgDd63/JRiABgM7ZOh4AGNwYnrLpf9EJAOieCgkAdK//+oJAAgCd00MCAMwD/QeS/ms8ALCbq6oZHTvw+a+qqhuqak1VvWc27kEgAQAeU1UtTPIXSV6d5Jgkp1fVMbv6OgIJAHRvwQyP7ToxyZrW2g9baw8k+XSSU3b1HeghAYDOzXJT62FJbpr087okL9jVF5mDQPL0/jttdmNVtaK1tnLoebDz/u5lTx96CsyAv3vsnJn9W1tVK5KsmDS0ctJ/f1N9dpvJ9aZiyYbprJj+FGAW+LvHnGmtrWytnTDpmByG1yU5fNLPy5Ks39VzEEgAgO25MsnyqnpKVe2Z5A1JLt3VF9FDAgA8ptba5qp6W5IvJVmY5PzW2rW7+joCCdOxhg3D8HePeaO1dlmSy2bzGtXaLu9LAQDYKXpIAIDBCSRMaS62CQYerarOr6rbq+qaoecCc0kg4VHmaptgYEqfTPKqoScBc00gYSpzsk0w8GittcuT3DX0PGCuCSRMZaptgg8baC4A7AYEEqYyJ9sEA8A2AglTmZNtggFgG4GEqczJNsEAsI1AwqO01jYn2bZN8HVJLpmNbYKBR6uqi5N8PckzqmpdVZ059JxgLtipFQAYnAoJADA4gQQAGJxAAgAMTiABAAYnkAAAgxNIAIDBCSQAwOAEEgBgcP8fJqo0yAouhMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the confusion matrix for better understanding\n",
    "cm =confusion_matrix(test_df['target'], y_classes)  \n",
    "index = [0,1]  \n",
    "columns = [0,1]  \n",
    "cm_df = pd.DataFrame(cm,columns,index)                      \n",
    "plt.figure(figsize=(10,6))  \n",
    "sns.heatmap(cm_df,annot=True,cmap=\"YlGnBu\",fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
